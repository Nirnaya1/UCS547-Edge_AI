{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Version 1:taking 1 ROI from each image and saving it in txt file\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "#first version : taking 1 ROI from each image and saving it in txt file\n",
    "#second version : we want multiple ROI from image\n",
    "#third version : we want to know the type of each ROI when they are not all car or all people\n",
    "\n",
    "imagefol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/images\"\n",
    "annotationfol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/labels\"\n",
    "\n",
    "if not os.path.exists(imagefol):\n",
    "    print(\"No Image Folder Found\")\n",
    "else:\n",
    "    imlist=os.listdir(imagefol) #imlist will have all the imagenames as a list\n",
    "if not os.path.exists(annotationfol):\n",
    "    os.makedirs(annotationfol)\n",
    "\n",
    "\n",
    "if imlist:\n",
    "    for im in imlist:\n",
    "        img=cv2.imread(os.path.join(imagefol,im)) #img is a 3d array containing the RGB image\n",
    "        #no of bits for the image = rows*cols*3*8\n",
    "        \n",
    "        r=cv2.selectROI(img) #returns x0 y0 width height\n",
    "    \n",
    "        frame=im[: -4]\n",
    "        dst_txt=frame + '.txt'\n",
    "        boxess=[]\n",
    "        with open(os.path.join(annotationfol,dst_txt),'w') as f:\n",
    "            boxess=[r[0],r[1],r[0]+r[2],r[1]+r[3]]\n",
    "            f.write('{} {} {} {}'.format(*boxess)+'\\n')\n",
    "            f.close()\n",
    "            #there are various annotation format requirements \n",
    "            #xmin ymin xmax ymax\n",
    "            #xmin ymin width height\n",
    "            #ymin xmin ymax xmax\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Version 2:taking multiple ROI from image\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "#first version : taking 1 ROI from each image and saving it in txt file\n",
    "#second version : we want multiple ROI from image\n",
    "#third version : we want to know the type of each ROI when they are not all car or all people\n",
    "\n",
    "imagefol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/images\"\n",
    "annotationfol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/labels\"\n",
    "\n",
    "if not os.path.exists(imagefol):\n",
    "    print(\"No Image Folder Found\")\n",
    "else:\n",
    "    imlist=os.listdir(imagefol) #imlist will have all the imagenames as a list\n",
    "if not os.path.exists(annotationfol):\n",
    "    os.makedirs(annotationfol)\n",
    "\n",
    "if imlist:\n",
    "    for im in imlist:\n",
    "        img=cv2.imread(os.path.join(imagefol,im)) #img is a 3d array containing the RGB image\n",
    "        #no of bits for the image = rows*cols*3*8\n",
    "        frame=im[: -4]\n",
    "        dst_txt=frame + '.txt'\n",
    "        with open(os.path.join(annotationfol,dst_txt),'w') as f:\n",
    "            while(1):\n",
    "                r=cv2.selectROI(img) #returns x0 y0 width height\n",
    "    \n",
    "                if r[0]<50 and r[1]<50:\n",
    "                    break\n",
    "    \n",
    "               \n",
    "                \n",
    "                boxess=[]\n",
    "                \n",
    "                boxess=[r[0],r[1],r[0]+r[2],r[1]+r[3]]\n",
    "                f.write('{} {} {} {}'.format(*boxess)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "                    #there are various annotation format requirements \n",
    "                    #xmin ymin xmax ymax\n",
    "                    #xmin ymin width height\n",
    "                    #ymin xmin ymax xmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Version 3: Select multiple ROI from each image and select the type of each ROI\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "#first version : taking 1 ROI from each image and saving it in txt file\n",
    "#second version : we want multiple ROI from image\n",
    "#third version : we want to know the type of each ROI when they are not all car or all people\n",
    "\n",
    "imagefol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/images\"\n",
    "annotationfol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/labels\"\n",
    "\n",
    "if not os.path.exists(imagefol):\n",
    "    print(\"No Image Folder Found\")\n",
    "else:\n",
    "    imlist=os.listdir(imagefol) #imlist will have all the imagenames as a list\n",
    "if not os.path.exists(annotationfol):\n",
    "    os.makedirs(annotationfol)\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale=1\n",
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "if imlist:\n",
    "    for im in imlist:\n",
    "        img=cv2.imread(os.path.join(imagefol,im)) #img is a 3d array containing the RGB image\n",
    "        #no of bits for the image = rows*cols*3*8\n",
    "    \n",
    "        \n",
    "    \n",
    "        shape=img.shape\n",
    "        height=shape[0]\n",
    "        width=shape[1]\n",
    "       \n",
    "        org=(00,20)\n",
    "        img=cv2.putText(img, \"next\", org,font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "         \n",
    "        org=(500,20)\n",
    "        img=cv2.putText(img, \"Car\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "    \n",
    "        org=(1000,20)\n",
    "        img=cv2.putText(img, \"Person\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "        \n",
    "        frame=im[: -4]\n",
    "        dst_txt=frame + '.txt'\n",
    "        with open(os.path.join(annotationfol,dst_txt),'w') as f:\n",
    "            while(1):\n",
    "                r=cv2.selectROI('selector',img) #returns x0 y0 width height\n",
    "    \n",
    "                if r[0]<50 and r[1]<50:\n",
    "                    break\n",
    "                \n",
    "                r1=cv2.selectROI('selector',img)\n",
    "                if r1[0]>500 and r1[0]<550 and r1[1]>0 and r1[1]<50: #manipulating and existing\n",
    "                    s=\"car\"  #assuming your car org was(500,20)\n",
    "                    clr=(255,140,140)\n",
    "    \n",
    "                if r1[0]>1000 and r1[0]<1050 and r1[1]>0 and r1[1]<50: #manipulating and \n",
    "                    s=\"person\"  #assuming your person org was(1000,20)\n",
    "                    clr=(150,255,150)\n",
    "                \n",
    "    \n",
    "                xmin=r[0]/width\n",
    "                ymin=r[1]/height\n",
    "                xmax=(r[0]+r[2])/width\n",
    "                ymax=(r[1]+r[3])/height\n",
    "                cv2.rectangle(img,(r[0],r[1]),((r[0]+r[2]),(r[1]+r[3])),clr,2)\n",
    "                line=s + \" \" +str(xmin)+\" \"+str(ymin)+\" \"+str(xmax)+\" \"+str(ymax)+\"\\n\"\n",
    "                f.write(line)\n",
    "        f.close()\n",
    "cv2.destroyAllWindows()\n",
    "                #there are various annotation format requirements \n",
    "                #xmin ymin xmax ymax\n",
    "                #xmin ymin width height\n",
    "                #ymin xmin ymax xmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Version 4: Make polygonal selection and select the type of ROI and save a black image with coloured ROI portions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "imagefol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/images\"\n",
    "annotationfol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/Poly_labels\"\n",
    "outputfol=\"/home/nirnaya/Desktop/Edge AI/annotation_app/Poly_images\"\n",
    "\n",
    "if not os.path.exists(imagefol):\n",
    "    print(\"No Image Folder Found\")\n",
    "else:\n",
    "    imlist=os.listdir(imagefol) #imlist will have all the imagenames as a list\n",
    "if not os.path.exists(annotationfol):\n",
    "    os.makedirs(annotationfol)\n",
    "if not os.path.exists(outputfol):\n",
    "    os.makedirs(outputfol)\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale=1\n",
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "if imlist:\n",
    "    for i in imlist:\n",
    "        poly_points=[]\n",
    "        im=cv2.imread(os.path.join(imagefol,i))\n",
    "        imb=np.zeros_like(im)\n",
    "        cv2.rectangle(im, (0, 0), (50, 30),color, 2)\n",
    "        cv2.rectangle(im, (500, 0), (560, 30),color, 2)\n",
    "        cv2.rectangle(im, (1000, 0), (1100, 30),color, 2)\n",
    "        org=(00,20)\n",
    "        im=cv2.putText(im, \"next\", org,font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "         \n",
    "        org=(500,20)\n",
    "        im=cv2.putText(im, \"Car\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "    \n",
    "        org=(1000,20)\n",
    "        im=cv2.putText(im, \"Person\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "    \n",
    "        plt.imshow(im)\n",
    "        \n",
    "        flag=1\n",
    "        while(flag):\n",
    "            pl=[]\n",
    "            while(1):\n",
    "                p=plt.ginput(1)\n",
    "                (px,py)=p[0][0],p[0][1]\n",
    "                if px>500 and py>0 and px<560 and py<30:\n",
    "                    type=\"car\"\n",
    "                    if pl:\n",
    "                        pl.insert(0,type)\n",
    "                    break\n",
    "                if px>1000 and py>0 and px<1100 and py<30:\n",
    "                    type=\"person\"\n",
    "                    if pl:\n",
    "                        pl.insert(0,type)\n",
    "                    break\n",
    "                if px<50 and py<30:\n",
    "                    plt.close()\n",
    "                    flag=0\n",
    "                    break\n",
    "                pl.append((int(px),int(py)))\n",
    "            if pl:\n",
    "                poly_points.append(pl)\n",
    "        #plt.show()\n",
    "        for a in poly_points:\n",
    "            pt=copy.deepcopy(a)\n",
    "            ty=pt.pop(0)\n",
    "            clr=(255,255,255)\n",
    "            if ty==\"car\":\n",
    "                clr=(100,100,255)\n",
    "            elif ty==\"person\":\n",
    "                clr=(150,255,150)\n",
    "            cv2.fillPoly(imb,[np.array(pt)],clr)\n",
    "        cv2.imshow('win',imb)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "        frame=i[: -4]\n",
    "        dst_txt=frame + '.txt'\n",
    "        dst_png=frame + '.png'\n",
    "        with open(os.path.join(annotationfol,dst_txt),'w') as f:\n",
    "            for b in poly_points:\n",
    "                f.write(str(b.pop(0))+\" \")\n",
    "                for a in b:\n",
    "                    f.write(\"(\"+str(a[0]) + \",\" + str(a[1])+\")\")\n",
    "                f.write(\"\\n\")\n",
    "        f.close()\n",
    "        cv2.imwrite(os.path.join(outputfol,dst_png),imb)\n",
    "#run for multiple images\n",
    "#save the segmented image using cv2.imwrite\n",
    "#try to save multiple polygons in the same image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Plot the bounding boxes from version 3 on the images give label and option to add more ROIs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "# Paths to the image and label folders\n",
    "image_folder = '/home/nirnaya/Desktop/Edge AI/annotation_app/images'\n",
    "label_folder = '/home/nirnaya/Desktop/Edge AI/annotation_app/labels'\n",
    "\n",
    "if not os.path.exists(imagefol):\n",
    "    print(\"No Image Folder Found\")\n",
    "if not os.path.exists(annotationfol):\n",
    "    print(\"No LabelFolder Found\")\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale=1\n",
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "# Function to draw bounding boxes and labels on an image\n",
    "def draw_labels_on_image(image_path, label_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    shape=image.shape\n",
    "    height=shape[0]\n",
    "    width=shape[1]\n",
    "    \n",
    "    # Read the labels from the file\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Draw each label\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        \n",
    "        label = parts[0]\n",
    "        xmin = int(float(parts[1])*width)\n",
    "        ymin = int(float(parts[2])*height)\n",
    "        xmax = int(float(parts[3])*width)\n",
    "        ymax = int(float(parts[4])*height)\n",
    "        \n",
    "        # Calculate the bounding box coordinates\n",
    "\n",
    "        if label=='car':\n",
    "            color=(255,140,140)\n",
    "        else:\n",
    "            color=(150,255,150)\n",
    "        \n",
    "        \n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax),color, 2)\n",
    "        \n",
    "        # Put the label text above the bounding box\n",
    "        cv2.putText(image, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,color, 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Process all images in the image folder\n",
    "for image_filename in os.listdir(image_folder):\n",
    "    if not image_filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        continue\n",
    "    \n",
    "    # Construct the full path for the image and label files\n",
    "    image_path = os.path.join(image_folder, image_filename)\n",
    "    label_path = os.path.join(label_folder, os.path.splitext(image_filename)[0] + '.txt')\n",
    "\n",
    "    while(1):\n",
    "        if os.path.exists(label_path):\n",
    "            # Draw labels on the image\n",
    "            annotated_image = draw_labels_on_image(image_path, label_path)\n",
    "\n",
    "            shape=annotated_image.shape\n",
    "            height=shape[0]\n",
    "            width=shape[1]\n",
    "\n",
    "            im=copy.deepcopy(annotated_image)\n",
    "\n",
    "            org=(00,20)\n",
    "            annotated_image=cv2.putText(annotated_image, \"next\", org,font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "\n",
    "            org=(500,20)\n",
    "            annotated_image=cv2.putText(annotated_image, \"add roi\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "\n",
    "            r=cv2.selectROI(annotated_image)\n",
    "            if r[0]<50 and r[1]<30:\n",
    "                break\n",
    "            if r[0]>500 and r[0]<550 and r[1]>0 and r[1]<30:\n",
    "                org=(00,20)\n",
    "                im=cv2.putText(im, \"done\", org,font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "\n",
    "                org=(500,20)\n",
    "                im=cv2.putText(im, \"car\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "\n",
    "                org=(1000,20)\n",
    "                im=cv2.putText(im, \"Person\", org, font, fontScale, color, thickness,cv2.LINE_AA)\n",
    "                \n",
    "                frame=image_filename[: -4]\n",
    "                dst_txt=frame+'.txt'\n",
    "                with open(os.path.join(label_folder,dst_txt),'a') as f:\n",
    "                    while (1):\n",
    "                        r1=cv2.selectROI('ROI selector',im)\n",
    "                        if r1[0]<50 and r1[1]<30:\n",
    "                            break\n",
    "                        r2=cv2.selectROI(im)\n",
    "                        if r2[0]>500 and r2[0]<550 and r2[1]>0 and r2[1]<30:\n",
    "                            s='car'\n",
    "                            clr=(255,140,140)\n",
    "                        if r2[0]>1000 and r2[0]<1050 and r2[1]>0 and r2[1]<30:\n",
    "                            s='person'\n",
    "                            clr=(150,255,150)\n",
    "\n",
    "                        xmin=r1[0]/width\n",
    "                        ymin=r1[1]/height\n",
    "                        xmax=(r1[0]+r1[2])/width\n",
    "                        ymax=(r1[1]+r1[3])/height\n",
    "                        cv2.rectangle(im,(r1[0],r1[1]),((r1[0]+r1[2]),(r1[1]+r1[3])),clr,2)\n",
    "                        line=s + \" \" +str(xmin)+\" \"+str(ymin)+\" \"+str(xmax)+\" \"+str(ymax)+\"\\n\"\n",
    "                        f.write(line)\n",
    "                f.close()\n",
    "\n",
    "        # Optionally, save the annotated image\n",
    "        # output_path = os.path.join('path_to_save_folder', image_filename)\n",
    "        # cv2.imwrite(output_path, annotated_image)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
