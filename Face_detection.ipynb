{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b225ad2-b67e-44f7-b6db-e5b7ef5896f6",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872747f-bc2b-4949-b98e-f75584a3852d",
   "metadata": {},
   "source": [
    "***\n",
    "version 1: Decting faces from the video feed and putting a rectangle around the faces\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdec31-8148-4bbf-a2e8-99355f2422f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade =cv2.CascadeClassifier(\"/home/nirnaya/Desktop/Edge AI/face_detector/res/haarcascade_frontalface_default.xml\")\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    #frame=cap.read()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "         print(\"Failed to capture frame\")\n",
    "         break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray_image=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    detections=face_cascade.detectMultiScale(gray_image,scaleFactor=1.1,minNeighbors=6)\n",
    "\n",
    "    for face in detections:\n",
    "        x,y,w,h=face\n",
    "        frame=cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    if cv2.waitKey(1)& 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af96557-b23a-439e-9fa5-cbdc76cf62a6",
   "metadata": {},
   "source": [
    "***\n",
    "Make png photo/add alpha chanel by removing white background providinf=g a threshold\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7973e5b4-258a-4700-ae5a-0cba30d6b5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "file_name=\"/home/nirnaya/Desktop/Edge AI/face_detector/res/download (1).jpeg\"\n",
    "src=cv2.imread(file_name,1)\n",
    "src1=255-src\n",
    "\n",
    "tmp=cv2.cvtColor(src1,cv2.COLOR_BGR2GRAY)\n",
    "_,alpha=cv2.threshold(tmp,20,255,cv2.THRESH_BINARY)\n",
    "\n",
    "b,g,r=cv2.split(src)\n",
    "rgba=[b,g,r,alpha]\n",
    "dst=cv2.merge(rgba,4)\n",
    "cv2.imwrite(\"apple.png\",dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f844b0-dc9b-4697-9809-423ee4137146",
   "metadata": {},
   "source": [
    "***\n",
    "Apply a png image to the face as a simple filter\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283efc2c-c023-4dae-805a-3306eb9026fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@157.405] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"/home/nirnaya/Desktop/Edge AI/face_detector/res/haarcascade_frontalface_default.xml\")\n",
    "png_image=\"/home/nirnaya/Desktop/Edge AI/face_detector/res/vecteezy_monkey-head-clipart-design-illustration_46339710.png\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detections = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=6)\n",
    "\n",
    "    for face in detections:\n",
    "        x, y, w, h = face\n",
    "        # Load and resize the PNG image with alpha channel\n",
    "        k = cv2.imread(png_image, cv2.IMREAD_UNCHANGED)\n",
    "        k1 = cv2.resize(k, (w, h))\n",
    "\n",
    "        # Separate the color and alpha channels\n",
    "        bgr = k1[:, :, :3]  # BGR channels\n",
    "        alpha = k1[:, :, 3] / 255.0  # Alpha channel normalized to 0-1\n",
    "\n",
    "        # Extract the region of interest from the frame\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Blend the PNG image and the ROI using the alpha channel\n",
    "        for c in range(0, 3):\n",
    "            roi[:, :, c] = roi[:, :, c] * (1 - alpha) + bgr[:, :, c] * alpha\n",
    "\n",
    "        # Place the blended image back into the frame\n",
    "        frame[y:y+h, x:x+w] = roi\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc68ae-5193-460a-95aa-fcb487beee43",
   "metadata": {},
   "source": [
    "***\n",
    "Track the faces in the video feed save the images and coordinates of the motion , plot the coordinates and show the motion of the faces on the captured image\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fab5d25-f545-49d8-a95c-19348e27d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@925.425] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as image_8.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "imagefol=\"/home/nirnaya/Desktop/Edge AI/face_detector/res/images\"\n",
    "annotationfol=\"/home/nirnaya/Desktop/Edge AI/face_detector/res/labels\" \n",
    "if not os.path.exists(imagefol):\n",
    "    os.makedirs(imagefol) \n",
    "if not os.path.exists(annotationfol):\n",
    "    os.makedirs(annotationfol)\n",
    "face_cascade =cv2.CascadeClassifier(\"/home/nirnaya/Desktop/Edge AI/face_detector/res/haarcascade_frontalface_default.xml\")\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "points={}\n",
    "while(1):\n",
    "    #frame=cap.read()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "         print(\"Failed to capture frame\")\n",
    "         break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_save=copy.deepcopy(frame)\n",
    "    gray_image=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    detections=face_cascade.detectMultiScale(gray_image,scaleFactor=1.1,minNeighbors=6)\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    for face in detections:\n",
    "        x,y,w,h=face\n",
    "        frame=cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        coord=(x+w/2,y+h/2)\n",
    "        if i not in points:\n",
    "            points[i] = []\n",
    "        points[i].append(coord)\n",
    "        i+=1\n",
    "        \n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        for i in range(1, 101):\n",
    "            i_name = 'image_' + str(i) + '.png'\n",
    "            t_name='image_'+str(i)+'.txt'\n",
    "            imlist = os.listdir(imagefol)\n",
    "            txlist=os.listdir(annotationfol)\n",
    "            if i_name not in imlist and t_name not in txlist:\n",
    "                cv2.imwrite(os.path.join(imagefol, i_name), frame_save)\n",
    "                print(f\"Image saved as {i_name}\")\n",
    "                with open(os.path.join(annotationfol,t_name),'w') as f:\n",
    "                    for a in points:\n",
    "                        f.write(str(points[a])+\" \")\n",
    "                        f.write(\"\\n\")\n",
    "                f.close\n",
    "                points={}\n",
    "                break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(imagefol) or not os.path.exists(annotationfol):\n",
    "    print(\"!!Check Folders!!\")\n",
    "else:\n",
    "    imlist=os.listdir(imagefol)\n",
    "    if len(imlist):\n",
    "        for im in imlist:\n",
    "            iname=im[: -4]\n",
    "            tname=iname+\".txt\"\n",
    "            img=cv2.imread(os.path.join(imagefol,im))\n",
    "            with open(os.path.join(annotationfol,tname),'r') as f:\n",
    "                lines=f.readlines()\n",
    "                coordinates_list = []\n",
    "                for line in lines:\n",
    "                    # Remove brackets and split by comma\n",
    "                    line = line.strip()[1:-1].split(\"), (\")\n",
    "                    \n",
    "                    # Convert the string coordinates to tuples of floats\n",
    "                    coordinates = []\n",
    "                    for point in line:\n",
    "                        x, y = point.replace('(','').replace(')','').split(',')\n",
    "                        coordinates.append((float(x), float(y)))\n",
    "                    \n",
    "                    coordinates_list.append(coordinates)\n",
    "\n",
    "                # Create a blank image\n",
    "                image = img\n",
    "\n",
    "                # Draw the lines\n",
    "                for coordinates in coordinates_list:\n",
    "                    # Convert coordinates to integer\n",
    "                    points = [(int(x), int(y)) for x, y in coordinates]\n",
    "                    \n",
    "                    # Draw line segments for the current list of coordinates\n",
    "                    for i in range(len(points)-1):\n",
    "                        cv2.line(image, points[i], points[i + 1], (0, 0, 255), 2)  # Red color with thickness of 2\n",
    "                    \n",
    "                    # Optionally, close the shape by drawing a line from the last point to the first\n",
    "                    # cv2.line(image, points[-1], points[0], (0, 0, 255), 2)\n",
    "\n",
    "                # Display the image\n",
    "            cv2.imshow('Image with Lines', image)\n",
    "            cv2.waitKey(0)\n",
    "f.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc674d-d70a-4c74-aee5-ff4f8530679b",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
